#version 430 core
#include "raytraceCommon.glsl"

// for per pixel inputs
#include <nbl/builtin/glsl/utils/normal_decode.glsl>
#include <nbl/builtin/glsl/random/xoroshiro.glsl>

// rng
layout(set = 2, binding = 0) uniform usamplerBuffer sampleSequence;
layout(set = 2, binding = 1) uniform usampler2D scramblebuf;
// vis buffer
layout(set = 2, binding = 2) uniform sampler2D depthbuf;
layout(set = 2, binding = 3) uniform usampler2D frontFacing_Object_Triangle;
layout(set = 2, binding = 4) uniform sampler2D encodedNormal;
layout(set = 2, binding = 5) uniform sampler2D uvCoords;
//layout(set = 2, binding = 6) uniform sampler2D barycentricDerivatives; // in the future we shall compute them from triangle vertex positions


#include "bin/material_declarations.glsl"
#include <nbl/builtin/glsl/ext/MitsubaLoader/material_compiler_compatibility_impl.glsl>
vec3 normalizedV;
vec3 nbl_glsl_MC_getNormalizedWorldSpaceV()
{
	return normalizedV;
}
vec3 normalizedN; // TODO
vec3 nbl_glsl_MC_getNormalizedWorldSpaceN()
{
	return normalizedN;
}
vec3 worldPosition;
vec3 nbl_glsl_MC_getWorldSpacePosition()
{
	return worldPosition;
}
mat2x3 dPosdScreen = mat2x3(vec3(0.0),vec3(0.0)); // TODO
mat2x3 nbl_glsl_MC_getdPos(in vec3 p)
{
	return dPosdScreen;
}
#define _NBL_USER_PROVIDED_MATERIAL_COMPILER_GLSL_BACKEND_FUNCTIONS_
#include <nbl/builtin/glsl/material_compiler/common.glsl>

//
///


// functions
vec3 rand3d(in uint _sample, inout nbl_glsl_xoroshiro64star_state_t scramble_state)
{
	uvec3 seqVal = texelFetch(sampleSequence,int(_sample)).xyz;
	seqVal ^= uvec3(nbl_glsl_xoroshiro64star(scramble_state),nbl_glsl_xoroshiro64star(scramble_state),nbl_glsl_xoroshiro64star(scramble_state));
    return vec3(seqVal)*uintBitsToFloat(0x2f800004u);
}

float linearizeZBufferVal(in float nonLinearZBufferVal)
{
	// 1-(Ax+B)/(Cx) = y
	// (Ax+B)/(Cx) = 1-y
	// x = B/(C(1-y)-A)
	// x = B/(C-A-Cy)
	// get back original Z: `row[2][3]/(row[3][2]-row[2][2]-y*row[3][2]) = x`
	// max Z: `B/(C-A)`
	// positive [0,1] Z: `B/(C-A-Cy)/(B/(C-A))`
	// positive [0,1] Z: `(C-A)/(C-A-Cy)`
	// positive [0,1] Z: `D/(D-Cy)`
    return 1.0/(pc.cummon.depthLinearizationConstant*nonLinearZBufferVal+1.0);
}

/*
float maxAbs1(in float val) 
{
	return abs(val);
}
float maxAbs2(in vec2 val)
{
	vec2 v = abs(val);
	return max(v.x,v.y);
}
float maxAbs3(in vec3 val)
{
	vec3 v = abs(val);
	return max(max(v.x,v.y),v.z);
}

float GET_MAGNITUDE(in float val)
{
	float x = abs(val);
	return uintBitsToFloat(floatBitsToUint(x)&2139095040u);
}

float ULP1(in float val, in uint accuracy)
{
	float x = abs(val);
	return uintBitsToFloat(floatBitsToUint(x) + accuracy)-x;
}
float ULP2(in vec2 val, in uint accuracy)
{
	float x = maxAbs2(val);
	return uintBitsToFloat(floatBitsToUint(x) + accuracy)-x;
}
float ULP3(in vec3 val, in uint accuracy)
{
	float x = maxAbs3(val);
	return uintBitsToFloat(floatBitsToUint(x) + accuracy)-x;
}
*/


struct SamplingData_t
{
	uint sampleID;
};
bool gen_sample_ray(out float maxT, out vec3 direction, out vec3 throughput, in SamplingData_t samplingData)
{
	maxT = FLT_MAX;
	direction = -nbl_glsl_MC_getNormalizedWorldSpaceV();
	throughput = vec3(1.0);
	return true;
}

void main()
{
	uvec2 outputLocation = gl_GlobalInvocationID.xy;
	if (all(lessThan(outputLocation,staticViewData.imageDimensions)))
	{
		ivec2 pixelCoord = ivec2(outputLocation);
		float revdepth = texelFetch(depthbuf,pixelCoord,0).r;

		const uint outputID = outputLocation.y*staticViewData.samplesPerRowPerDispatch+outputLocation.x*staticViewData.samplesPerPixelPerDispatch;

		SamplingData_t samplingData;
		
		bool alive = false;
		nbl_glsl_MC_precomputed_t precomputed;
		nbl_glsl_MC_oriented_material_t material;
		nbl_glsl_xoroshiro64star_state_t start_scramble;
		vec2 uv;
		if (revdepth>0.0)
		{			
			// vis buffer read
			const uvec2 visBuffer = texelFetch(frontFacing_Object_Triangle,pixelCoord,0).rg;
			mat2x3 dBarydScreen;/*
			{
				// TODO: future https://diaryofagraphicsprogrammer.blogspot.com/2018/03/triangle-visibility-buffer.html
				vec4 data;// = texelFetch(barycentricDerivatives,pixelCoord,0);
				dBarydScreen[0] = vec3(data.rg,-data.r-data.g);
				dBarydScreen[1] = vec3(data.ba,-data.b-data.a);
			}
			dPosdScreen = mat3(vPos[0],vPos[1],vPos[2])*dBarydScreen;
			*/
			// init scramble
			start_scramble = texelFetch(scramblebuf,pixelCoord,0).rg;
			// tmp gbuffer reads
			const vec2 normalBuffer = texelFetch(encodedNormal,pixelCoord,0).rg;
			uv = texelFetch(uvCoords,pixelCoord,0).xy;
			
			// unproject
			{
				const mat4x3 frustumCornersToCamera = pc.cummon.frustumCornersToCamera;
				const vec2 NDC = vec2(outputLocation)*staticViewData.rcpPixelSize+staticViewData.rcpHalfPixelSize;
				
				const vec3 V = mix(frustumCornersToCamera[1]*NDC.x+frustumCornersToCamera[0],frustumCornersToCamera[3]*NDC.x+frustumCornersToCamera[2],NDC.yyy); // could maybe compute this more precisely
				worldPosition = pc.cummon.cameraPosition-V*linearizeZBufferVal(revdepth);
				normalizedV = normalize(V);
			}
			
			// decode vis buffer
			bool frontfacing;
			vec3 emissive;
			{
				frontfacing = visBuffer[0]<0x80000000u;
				const uint objectID = visBuffer[0]&0x7fffffffu;
				const uint triangleID = visBuffer[1];
				
				//
				precomputed = nbl_glsl_MC_precomputeData(frontfacing);
				material = nbl_glsl_MC_material_data_t_getOriented(InstData.data[objectID].material,precomputed.frontface);

				//
				emissive = nbl_glsl_MC_oriented_material_t_getEmissive(material);

				// normally we'd use MeshPackerV2's vertex attribute data for this, but now we read from temporary GBuffer
				const vec3 normal = nbl_glsl_NormalDecode_signedSpherical(normalBuffer);
				normalizedN.x = dot(InstData.data[objectID].normalMatrixRow0,normal);
				normalizedN.y = dot(InstData.data[objectID].normalMatrixRow1,normal);
				normalizedN.z = dot(InstData.data[objectID].normalMatrixRow2,normal);
			}
			
			//
			vec3 acc;
			if (pc.cummon.rcpFramesDispatched<1.0)
				acc = fetchAccumulation(pixelCoord)+emissive/float(pc.cummon.framesDispatched-1u);
			else
				acc = emissive;

			//

			storeAccumulation(acc,pixelCoord);
			alive = true;
		}
#ifdef USE_OPTIX_DENOISER
		// TODO: translate normal into float16_t buff
#endif

		for (uint i=0u; i<staticViewData.samplesPerPixelPerDispatch; i++)
		{
			vec3 direction; // TODO: just use nbl_glsl_LightSample?
			float maxT;
			vec4 throughput = vec4(0.0,0.0,0.0,-1.0); // -1 needs to be there to ensure no backface culling on rays

			bool validRay = false;
			if (alive)
			{
				samplingData.sampleID = pc.cummon.samplesComputedPerPixel+i;
				validRay = gen_sample_ray(maxT,direction,throughput.rgb,samplingData);
			}
			
			// TODO: repack rays in smem for coalescing
			const uint realOutputID = outputID+i;
			if (validRay)
			{
				throughput /= float(staticViewData.samplesPerPixelPerDispatch);

				const float tt = 1.0;
				rays[realOutputID].origin = nbl_glsl_MC_getWorldSpacePosition()+nbl_glsl_MC_getNormalizedWorldSpaceV()*tt;//-direction*0.5*maxT;/*+newray.direction*err?; TODO */
				rays[realOutputID].maxT = tt*2.0;
				rays[realOutputID].direction = -nbl_glsl_MC_getNormalizedWorldSpaceV()*tt;
				rays[realOutputID].mask = -1;
				rays[realOutputID]._active = 1;
				rays[realOutputID].backfaceCulling = int(packHalf2x16(throughput.ab));
				rays[realOutputID].useless_padding = int(packHalf2x16(throughput.gr));
			}
			else
			{
				rays[realOutputID].maxT = 0.0;
				rays[realOutputID].mask = 0;
				rays[realOutputID]._active = 0;
			}
		}
	}
}